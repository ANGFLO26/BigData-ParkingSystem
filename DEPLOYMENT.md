# ğŸ“¦ HÆ°á»›ng dáº«n Deploy trÃªn Nhiá»u MÃ¡y

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ deploy há»‡ thá»‘ng Ä‘á»— xe trÃªn 6 mÃ¡y Ubuntu riÃªng biá»‡t.

## ğŸ”§ Chuáº©n bá»‹

### YÃªu cáº§u cho má»—i mÃ¡y:
- Ubuntu 20.04+ hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- Docker Engine 20.10+
- Docker Compose 2.0+
- Táº¥t cáº£ mÃ¡y trong cÃ¹ng máº¡ng LAN
- Tá»‘i thiá»ƒu 2GB RAM má»—i mÃ¡y (khuyáº¿n nghá»‹ 4GB+)

### Network Setup:
- Äáº£m báº£o táº¥t cáº£ cÃ¡c mÃ¡y cÃ³ thá»ƒ ping Ä‘Æ°á»£c nhau
- Firewall cho phÃ©p cÃ¡c ports sau:
  - 2181 (Zookeeper)
  - 9092 (Kafka)
  - 6379 (Redis)
  - 9042 (Cassandra)
  - 8080, 7077 (Spark/Airflow)
  - 8501 (Dashboard)

## ğŸ“‹ BÆ°á»›c 1: Setup trÃªn MÃ¡y Master

1. **Clone hoáº·c copy project:**
```bash
cd ~
git clone <repository> bigdata
cd bigdata
```

2. **Táº¡o file .env:**
```bash
cp .env.example .env
nano .env
```

Cáº­p nháº­t cÃ¡c IP addresses:
```env
NODE1_IP=192.168.1.10
NODE2_IP=192.168.1.11
NODE3_IP=192.168.1.12
NODE4_IP=192.168.1.13
NODE5_IP=192.168.1.14
NODE6_IP=192.168.1.15
```

## ğŸ“¦ BÆ°á»›c 2: Copy Project lÃªn CÃ¡c MÃ¡y Worker

### Option 1: Sá»­ dá»¥ng SCP
```bash
# Copy lÃªn Node 1
scp -r bigdata/ user@192.168.1.10:/home/user/

# Copy lÃªn Node 2
scp -r bigdata/ user@192.168.1.11:/home/user/

# ... láº·p láº¡i cho cÃ¡c node khÃ¡c
```

### Option 2: Sá»­ dá»¥ng Git
TrÃªn má»—i mÃ¡y worker:
```bash
git clone <repository>
cd bigdata
cp .env.example .env
# Cáº­p nháº­t .env vá»›i IP Ä‘Ãºng
```

## ğŸš€ BÆ°á»›c 3: Deploy tá»«ng Node

### Node 2: Kafka + Producer (CHáº Y Äáº¦U TIÃŠN)
```bash
ssh user@192.168.1.11
cd bigdata
docker-compose --profile node2 up -d

# Kiá»ƒm tra Kafka Ä‘Ã£ sáºµn sÃ ng
docker logs -f parking-kafka
# Äá»£i tháº¥y message "started"
```

### Node 5: Redis Cache
```bash
ssh user@192.168.1.14
cd bigdata
docker-compose --profile node5 up -d

# Test Redis
docker exec -it parking-redis-cache redis-cli -n 2 PING
# Káº¿t quáº£: PONG
```

### Node 4: Cassandra
```bash
ssh user@192.168.1.13
cd bigdata
docker-compose --profile node4 up -d

# Äá»£i Cassandra khá»Ÿi Ä‘á»™ng (30-60 giÃ¢y)
sleep 60

# Táº¡o schema
docker exec -it parking-cassandra cqlsh -f /docker-entrypoint-initdb.d/create-tables.cql

# Hoáº·c thá»§ cÃ´ng:
docker exec -it parking-cassandra cqlsh
# Copy paste ná»™i dung tá»« cassandra/schema.cql
```

### Node 3: Spark Streaming
```bash
ssh user@192.168.1.12
cd bigdata

# Äáº£m báº£o .env cÃ³ Ä‘Ãºng IP cá»§a Kafka, Redis, Cassandra
docker-compose --profile node3 up -d

# Kiá»ƒm tra logs
docker logs -f parking-spark-master
# Äá»£i tháº¥y "Spark Streaming started!"
```

### Node 6: Dashboard
```bash
ssh user@192.168.1.15
cd bigdata
docker-compose --profile node6 up -d

# Truy cáº­p: http://192.168.1.15:8501
```

### Node 1: Airflow
```bash
ssh user@192.168.1.10
cd bigdata
docker-compose --profile node1 up -d

# Äá»£i Airflow khá»Ÿi Ä‘á»™ng (1-2 phÃºt)
# Truy cáº­p: http://192.168.1.10:8080
# Username/Password: airflow/airflow
```

## âœ… BÆ°á»›c 4: Kiá»ƒm tra Há»‡ thá»‘ng

### 1. Kiá»ƒm tra Producer gá»­i data:
```bash
# TrÃªn Node 2
docker logs parking-camera-producer
# Pháº£i tháº¥y: "âœ… Event #X sent: ..."
```

### 2. Kiá»ƒm tra Kafka nháº­n messages:
```bash
# TrÃªn Node 2
docker exec -it parking-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic parking-events \
  --from-beginning
```

### 3. Kiá»ƒm tra Spark xá»­ lÃ½:
```bash
# TrÃªn Node 3
docker logs parking-spark-master
# Pháº£i tháº¥y: "âœ… Redis cache updated: X occupied"
```

### 4. Kiá»ƒm tra Redis cÃ³ data:
```bash
# TrÃªn Node 5
docker exec -it parking-redis-cache redis-cli -n 2
> KEYS parking:*
> GET parking:occupied_count
> GET parking:location:A1
```

### 5. Kiá»ƒm tra Dashboard:
Má»Ÿ trÃ¬nh duyá»‡t: `http://NODE6_IP:8501`
- Pháº£i tháº¥y tá»•ng quan sá»‘ vá»‹ trÃ­
- Pháº£i tháº¥y cÃ¡c xe Ä‘ang Ä‘á»— vá»›i thÃ´ng tin tiá»n

## ğŸ” Troubleshooting

### Lá»—i: Kafka khÃ´ng connect Ä‘Æ°á»£c
**NguyÃªn nhÃ¢n:** IP khÃ´ng Ä‘Ãºng trong .env
**Giáº£i phÃ¡p:** 
- Kiá»ƒm tra `NODE2_IP` trong .env cá»§a Node 3
- Kiá»ƒm tra `KAFKA_BOOTSTRAP_SERVERS` cÃ³ Ä‘Ãºng khÃ´ng

### Lá»—i: Redis connection timeout
**NguyÃªn nhÃ¢n:** Firewall block port 6379
**Giáº£i phÃ¡p:**
```bash
sudo ufw allow 6379/tcp
```

### Lá»—i: Spark khÃ´ng nháº­n Ä‘Æ°á»£c data tá»« Kafka
**NguyÃªn nhÃ¢n:** Kafka chÆ°a expose Ä‘Ãºng IP
**Giáº£i phÃ¡p:**
- Trong docker-compose.yml cá»§a Node 2, Ä‘áº£m báº£o `KAFKA_ADVERTISED_LISTENERS` cÃ³ IP cá»§a Node 2
- Restart Kafka: `docker-compose restart kafka`

### Lá»—i: Dashboard khÃ´ng hiá»ƒn thá»‹ data
**NguyÃªn nhÃ¢n:** Redis connection error
**Giáº£i phÃ¡p:**
- Kiá»ƒm tra `REDIS_CACHE_HOST` trong .env cá»§a Node 6
- Test connection: `docker exec parking-dashboard ping ${REDIS_CACHE_HOST}`

## ğŸ“Š Thá»© tá»± khá»Ÿi Ä‘á»™ng Ä‘Ãºng:

1. **Node 2** (Kafka) - Pháº£i cháº¡y Ä‘áº§u tiÃªn
2. **Node 5** (Redis) - CÃ³ thá»ƒ cháº¡y song song
3. **Node 4** (Cassandra) - Cáº§n thá»i gian khá»Ÿi Ä‘á»™ng
4. **Node 3** (Spark) - Sau khi Kafka, Redis, Cassandra Ä‘Ã£ sáºµn sÃ ng
5. **Node 6** (Dashboard) - Cáº§n Redis sáºµn sÃ ng
6. **Node 1** (Airflow) - CÃ³ thá»ƒ cháº¡y cuá»‘i cÃ¹ng

## ğŸ”„ Script tá»± Ä‘á»™ng:

Táº¡o file `deploy-all.sh` trÃªn mÃ¡y master:

```bash
#!/bin/bash
# Deploy all nodes (cháº¡y tá»« mÃ¡y master, SSH vÃ o cÃ¡c mÃ¡y khÃ¡c)

NODES=(
    "user@192.168.1.11:2"
    "user@192.168.1.14:5"
    "user@192.168.1.13:4"
    "user@192.168.1.12:3"
    "user@192.168.1.15:6"
    "user@192.168.1.10:1"
)

for node_info in "${NODES[@]}"; do
    IFS=':' read -r user_host node_num <<< "$node_info"
    echo "ğŸš€ Deploying Node $node_num on $user_host..."
    ssh "$user_host" "cd bigdata && docker-compose --profile node$node_num up -d"
done
```

Cháº¡y:
```bash
chmod +x deploy-all.sh
./deploy-all.sh
```

## ğŸ“ LÆ°u Ã½:

1. **IP Address:** Äáº£m báº£o cÃ¡c IP trong .env khá»›p vá»›i IP thá»±c cá»§a tá»«ng mÃ¡y
2. **Network:** Táº¥t cáº£ mÃ¡y pháº£i trong cÃ¹ng subnet
3. **Ports:** Má»Ÿ firewall cho cÃ¡c ports cáº§n thiáº¿t
4. **Thá»© tá»±:** TuÃ¢n thá»§ thá»© tá»± khá»Ÿi Ä‘á»™ng á»Ÿ trÃªn
5. **Timing:** Äá»£i cÃ¡c service khá»Ÿi Ä‘á»™ng xong trÆ°á»›c khi cháº¡y service phá»¥ thuá»™c

