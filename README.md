# ğŸš— Há»‡ Thá»‘ng Äá»— Xe ThÃ´ng Minh - Distributed Big Data System

Há»‡ thá»‘ng tÃ­nh tiá»n Ä‘á»— xe theo thá»i gian thá»±c sá»­ dá»¥ng Kafka, Spark Structured Streaming, Redis, Cassandra vÃ  Streamlit Dashboard.

## ğŸ“‹ Tá»•ng quan

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y phÃ¢n tÃ¡n trÃªn 6 mÃ¡y Ubuntu, má»—i mÃ¡y Ä‘áº£m nhiá»‡m má»™t chá»©c nÄƒng riÃªng:

- **Node 1**: Airflow + Redis (Celery) - Äiá»u phá»‘i & giÃ¡m sÃ¡t
- **Node 2**: Camera Producer + Kafka Broker - MÃ´ phá»ng camera AI
- **Node 3**: Spark Streaming Processor - Xá»­ lÃ½ realtime & tÃ­nh tiá»n
- **Node 4**: Cassandra Database - LÆ°u trá»¯ lá»‹ch sá»­
- **Node 5**: Redis Cache - Cache realtime
- **Node 6**: Streamlit Dashboard - GUI hiá»ƒn thá»‹ tráº¡ng thÃ¡i

## ğŸ”§ CÃ i Ä‘áº·t

### YÃªu cáº§u

- Docker vÃ  Docker Compose trÃªn má»—i mÃ¡y
- Python 3.9+ (náº¿u cháº¡y khÃ´ng dÃ¹ng Docker)
- Táº¥t cáº£ cÃ¡c mÃ¡y trong cÃ¹ng máº¡ng LAN

### BÆ°á»›c 1: Clone project

TrÃªn mÃ¡y master, clone repository:
```bash
git clone <repository-url>
cd bigdata
```

### BÆ°á»›c 2: Cáº¥u hÃ¬nh IP addresses

Copy file `.env.example` thÃ nh `.env` vÃ  cáº­p nháº­t IP addresses cho tá»«ng node:

```bash
cp .env.example .env
nano .env
```

Cáº­p nháº­t cÃ¡c IP addresses:
```env
# Node 1: Airflow + Redis (Celery)
NODE1_IP=192.168.1.10

# Node 2: Camera Producer + Kafka Broker
NODE2_IP=192.168.1.11

# Node 3: Spark Streaming Processor
NODE3_IP=192.168.1.12

# Node 4: Cassandra Database
NODE4_IP=192.168.1.13

# Node 5: Redis (Realtime Cache)
NODE5_IP=192.168.1.14

# Node 6: Streamlit Dashboard
NODE6_IP=192.168.1.15
```

### BÆ°á»›c 3: Copy project lÃªn cÃ¡c mÃ¡y worker

Copy toÃ n bá»™ thÆ° má»¥c `bigdata` lÃªn tá»«ng mÃ¡y worker:

```bash
# TrÃªn mÃ¡y master
scp -r bigdata/ user@node1-ip:/home/user/
scp -r bigdata/ user@node2-ip:/home/user/
# ... láº·p láº¡i cho cÃ¡c node khÃ¡c
```

### BÆ°á»›c 4: Cháº¡y tá»«ng node

TrÃªn má»—i mÃ¡y, cháº¡y node tÆ°Æ¡ng á»©ng:

#### Node 1 - Airflow + Redis (Celery)
```bash
cd bigdata
NODE_TYPE=node1 docker-compose --profile node1 up -d
```

#### Node 2 - Camera Producer + Kafka
```bash
cd bigdata
NODE_TYPE=node2 docker-compose --profile node2 up -d
```

#### Node 3 - Spark Streaming
```bash
cd bigdata
NODE_TYPE=node3 docker-compose --profile node3 up -d
```

#### Node 4 - Cassandra
```bash
cd bigdata
NODE_TYPE=node4 docker-compose --profile node4 up -d

# Sau khi Cassandra khá»Ÿi Ä‘á»™ng, táº¡o schema:
docker exec -it parking-cassandra cqlsh -f /docker-entrypoint-initdb.d/schema.cql
# Hoáº·c thá»§ cÃ´ng:
docker exec -it parking-cassandra cqlsh
# Sau Ä‘Ã³ cháº¡y lá»‡nh trong cassandra/schema.cql
```

#### Node 5 - Redis Cache
```bash
cd bigdata
NODE_TYPE=node5 docker-compose --profile node5 up -d
```

#### Node 6 - Streamlit Dashboard
```bash
cd bigdata
NODE_TYPE=node6 docker-compose --profile node6 up -d
```

### BÆ°á»›c 5: Khá»Ÿi táº¡o Cassandra Schema

TrÃªn Node 4, sau khi Cassandra Ä‘Ã£ khá»Ÿi Ä‘á»™ng:

```bash
docker exec -it parking-cassandra cqlsh
```

Cháº¡y lá»‡nh trong file `cassandra/schema.cql`:

```sql
CREATE KEYSPACE IF NOT EXISTS parking_system
WITH REPLICATION = {
    'class': 'SimpleStrategy',
    'replication_factor': 1
};

USE parking_system;

CREATE TABLE IF NOT EXISTS parking_history (
    timestamp TIMESTAMP,
    license_plate TEXT,
    location TEXT,
    status_code TEXT,
    parking_duration_minutes DECIMAL,
    parking_fee DECIMAL,
    PRIMARY KEY ((license_plate), timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC);
```

## ğŸš€ Sá»­ dá»¥ng

### Kiá»ƒm tra tráº¡ng thÃ¡i

1. **Kafka**: Kiá»ƒm tra topic `parking-events`
   ```bash
   docker exec -it parking-kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic parking-events
   ```

2. **Spark Streaming**: Xem logs
   ```bash
   docker logs -f parking-spark-master
   ```

3. **Redis Cache**: Kiá»ƒm tra keys
   ```bash
   docker exec -it parking-redis-cache redis-cli -n 2
   > KEYS parking:*
   ```

4. **Dashboard**: Truy cáº­p `http://NODE6_IP:8501`

5. **Airflow**: Truy cáº­p `http://NODE1_IP:8080` (username/password: airflow/airflow)

## ğŸ’° TÃ­nh tiá»n Ä‘á»— xe

Há»‡ thá»‘ng tÃ­nh tiá»n theo cÃ´ng thá»©c:
- **1 phÃºt = 10,000 VNÄ**
- TÃ­nh chÃ­nh xÃ¡c theo phÃºt (cÃ³ thá»ƒ cÃ³ sá»‘ tháº­p phÃ¢n)
- VÃ­ dá»¥: Äá»— 15 phÃºt 30 giÃ¢y = 15.5 phÃºt = 155,000 VNÄ

## ğŸ“Š Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 1    â”‚  Airflow + Redis (Celery)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 2    â”‚                   â”‚   Node 3    â”‚
â”‚ Camera +    â”‚ â”€â”€Kafkaâ”€â”€>        â”‚   Spark     â”‚
â”‚   Kafka     â”‚                   â”‚ Streaming   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Node 4    â”‚     â”‚   Node 5    â”‚     â”‚   Node 6    â”‚
            â”‚  Cassandra  â”‚     â”‚   Redis     â”‚     â”‚ Dashboard   â”‚
            â”‚  (History)  â”‚     â”‚  (Realtime) â”‚     â”‚  (GUI)      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Troubleshooting

### Kafka khÃ´ng nháº­n Ä‘Æ°á»£c messages
- Kiá»ƒm tra Kafka broker Ä‘ang cháº¡y: `docker ps | grep kafka`
- Kiá»ƒm tra producer logs: `docker logs parking-camera-producer`

### Spark khÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c data
- Kiá»ƒm tra Spark logs: `docker logs parking-spark-master`
- Kiá»ƒm tra Kafka connection tá»« Spark
- Kiá»ƒm tra Redis connection

### Dashboard khÃ´ng hiá»ƒn thá»‹ data
- Kiá»ƒm tra Redis connection
- Kiá»ƒm tra Redis cÃ³ data: `docker exec parking-redis-cache redis-cli -n 2 KEYS parking:*`
- Kiá»ƒm tra dashboard logs: `docker logs parking-dashboard`

### Cassandra connection error
- Äá»£i Cassandra khá»Ÿi Ä‘á»™ng hoÃ n táº¥t (cÃ³ thá»ƒ máº¥t 30-60 giÃ¢y)
- Kiá»ƒm tra schema Ä‘Ã£ Ä‘Æ°á»£c táº¡o chÆ°a
- Kiá»ƒm tra Cassandra logs: `docker logs parking-cassandra`

## ğŸ“ Files quan trá»ng

- `docker-compose.yml`: Cáº¥u hÃ¬nh Docker cho táº¥t cáº£ nodes
- `.env`: Cáº¥u hÃ¬nh IP addresses vÃ  ports
- `producer/camera_producer.py`: Camera Producer gá»­i events lÃªn Kafka
- `spark/spark_streaming.py`: Spark Streaming xá»­ lÃ½ vÃ  tÃ­nh tiá»n
- `dashboard/app.py`: Streamlit Dashboard
- `cassandra/schema.cql`: Cassandra database schema
- `airflow/dags/parking_system_dag.py`: Airflow DAG

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

Há»‡ thá»‘ng Ä‘Æ°á»£c phÃ¡t triá»ƒn cho bÃ i táº­p Big Data - Distributed System

# BigData-ParkingSystem
